{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled14.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOUDEJhydKaJhUEXi38ZA2R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumukhasrivatsa/PyTorch-Learnings/blob/main/Backpropogation%20through%202%20different%20networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzSbeIgKEyjg"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "seed=420\n",
        "a=[]\n",
        "b=[]\n",
        "images=[]\n",
        "print(type(a))\n",
        "random.seed(69)\n",
        "for i in range(1000):\n",
        "  \n",
        "  a.append([random.randint(1,100),random.randint(1,10),random.randint(1,1009),random.randint(1,1088)])\n",
        "  b.append(random.randint(1,11))\n",
        "  images.append(np.random.randint(0,255,(20,20)))\n",
        "\n",
        "\n",
        "#converting to np array\n",
        "a=np.array(a)\n",
        "print(type(a))\n",
        "b=np.array(b)\n",
        "#converting to a torch tensor\n",
        "a=torch.from_numpy(a)\n",
        "\n",
        "print(type(a))\n",
        "b=torch.from_numpy(b)\n",
        "\n",
        "#changing the type of the torch cuz grad works only on float32\n",
        "\n",
        "a=a.type(dtype=torch.float32)\n",
        "a.requires_grad=True\n",
        "print(type(a))\n",
        "\n",
        "b=b.type(dtype=torch.float32)\n",
        "b.requires_grad=True\n",
        "print(a)\n",
        "\n",
        "#making a class for neural network\n",
        "import torch.nn as nn\n",
        "\n",
        "class netA(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(netA,self).__init__()\n",
        "    self.l1=nn.Linear(4,4)\n",
        "    \n",
        "    print(type(self.l1))\n",
        "    self.l2=nn.Linear(4,4)\n",
        "    self.l3=nn.Linear(4,4)\n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.l1(x)\n",
        "    \n",
        "    x=self.l2(x)\n",
        "    x=self.l3(x)\n",
        "    return x\n",
        "\n",
        "obj=netA()\n",
        "yhat=obj.forward(a)\n",
        "print(yhat[0])\n",
        "y=torch.mean(yhat)\n",
        "y.backward()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "noise=[]\n",
        "noise.append([random.randint(1,100),random.randint(1,10),random.randint(1,1009),random.randint(1,1088),random.randint(1,1088),random.randint(1,1088)])\n",
        "noise=np.asarray(noise,float)\n",
        "noise=torch.from_numpy(noise)\n",
        "noise=noise.type(dtype=torch.float32)\n",
        "\n",
        "class noise_to_matrix(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(noise_to_matrix,self).__init__()\n",
        "    self.l1=nn.Linear(6,4)\n",
        "    self.l2=nn.Linear(4,4)\n",
        "    self.l3=nn.Linear(4,4)\n",
        "\n",
        "  def forward(self,noise):\n",
        "    noise=self.l1(noise)\n",
        "    noise=self.l2(noise)\n",
        "    matrix=self.l3(noise)\n",
        "\n",
        "    return matrix\n",
        "\n",
        "\n",
        "obj=noise_to_matrix()\n",
        "mat=obj.forward(noise)\n",
        "mat=torch.reshape(mat,(2,2))\n",
        "print(mat)\n",
        "\n",
        "for name, param in obj.named_parameters():\n",
        "  print(name,param)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#creating a random image\n",
        "image=np.random.randint(0,255,(2,2))\n",
        "image=torch.from_numpy(image)\n",
        "image=image.type(dtype=torch.float32)\n",
        "\n",
        "print(image)\n",
        "\n",
        "image_temp=image\n",
        "\n",
        "image=image*mat\n",
        "\n",
        "#creating a network to convolve\n",
        "\n",
        "print(image)\n",
        "\n",
        "image_for_nn=torch.flatten(image)\n",
        "\n",
        "class image_to_loss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(image_to_loss,self).__init__()\n",
        "    self.l1=nn.Linear(4,4)\n",
        "    self.l2=nn.Linear(4,2)\n",
        "    self.l3=nn.Linear(2,1)\n",
        "\n",
        "  def forward(self,img):\n",
        "    noise=self.l1(img)\n",
        "    noise=self.l2(noise)\n",
        "    output=self.l3(noise)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "obj1=image_to_loss()\n",
        "yhat=obj1.forward(image_for_nn)\n",
        "loss=yhat-11\n",
        "loss.backward()\n",
        "print(loss)\n",
        "optimizer = torch.optim.SGD(obj.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer.step()\n",
        "\n",
        "for name, param in obj.named_parameters():\n",
        "  print(name,param)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSFR8RhsW2dj",
        "outputId": "48d63f11-fafa-477d-d010-8b6fbd60f7b2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-79.4743, -54.4934],\n",
            "        [ 51.3098, -98.1225]], grad_fn=<ReshapeAliasBackward0>)\n",
            "l1.weight Parameter containing:\n",
            "tensor([[ 0.1233, -0.0757, -0.3559, -0.0195,  0.1845, -0.2578],\n",
            "        [ 0.2356, -0.0958,  0.1382,  0.0702, -0.0058, -0.0226],\n",
            "        [ 0.1147, -0.0500, -0.0372,  0.1782,  0.2970, -0.0825],\n",
            "        [ 0.0719, -0.2494,  0.0414,  0.2188, -0.1176,  0.1644]],\n",
            "       requires_grad=True)\n",
            "l1.bias Parameter containing:\n",
            "tensor([-0.1994, -0.3753,  0.1785,  0.0494], requires_grad=True)\n",
            "l2.weight Parameter containing:\n",
            "tensor([[-0.4178, -0.2737, -0.4337, -0.2776],\n",
            "        [-0.4719, -0.1556,  0.2299,  0.0104],\n",
            "        [-0.4506, -0.2203,  0.4314,  0.2588],\n",
            "        [-0.4920,  0.4905, -0.2603,  0.3982]], requires_grad=True)\n",
            "l2.bias Parameter containing:\n",
            "tensor([-0.1835,  0.2097, -0.0732, -0.1898], requires_grad=True)\n",
            "l3.weight Parameter containing:\n",
            "tensor([[ 0.2762, -0.2292, -0.1438, -0.2588],\n",
            "        [ 0.3585, -0.1895, -0.0421, -0.2239],\n",
            "        [ 0.0681, -0.1049,  0.1619,  0.2465],\n",
            "        [ 0.1933, -0.2403, -0.3508, -0.2050]], requires_grad=True)\n",
            "l3.bias Parameter containing:\n",
            "tensor([-0.3942,  0.2579, -0.0948,  0.2661], requires_grad=True)\n",
            "tensor([[ 31., 188.],\n",
            "        [ 94.,   0.]])\n",
            "tensor([[ -2463.7048, -10244.7578],\n",
            "        [  4823.1230,     -0.0000]], grad_fn=<MulBackward0>)\n",
            "tensor([541.5284], grad_fn=<SubBackward0>)\n",
            "l1.weight Parameter containing:\n",
            "tensor([[ 1.2171, -0.0465,  8.7446,  1.2639,  4.2826,  3.3299],\n",
            "        [-0.6986, -0.1207, -7.6345, -1.0260, -3.5060, -3.0869],\n",
            "        [ 0.0277, -0.0523, -0.7613,  0.0760, -0.0291, -0.3680],\n",
            "        [-1.1142, -0.2810, -9.8272, -1.1729, -4.5617, -3.7262]],\n",
            "       requires_grad=True)\n",
            "l1.bias Parameter containing:\n",
            "tensor([-0.1849, -0.3878,  0.1773,  0.0336], requires_grad=True)\n",
            "l2.weight Parameter containing:\n",
            "tensor([[-2.0182,  0.4492,  0.0209,  0.1282],\n",
            "        [-1.1038,  0.1298,  0.4094,  0.1706],\n",
            "        [ 2.4948, -1.5508, -0.4053, -0.4880],\n",
            "        [ 5.4877, -2.2105, -1.9590, -1.1180]], requires_grad=True)\n",
            "l2.bias Parameter containing:\n",
            "tensor([-0.1765,  0.2125, -0.0862, -0.2163], requires_grad=True)\n",
            "l3.weight Parameter containing:\n",
            "tensor([[-3.8417e-03, -1.5507e+00, -1.6576e+00, -2.3368e+00],\n",
            "        [ 1.3617e+00,  4.5444e+00,  5.3805e+00,  7.2196e+00],\n",
            "        [-1.7337e+00, -8.6067e+00, -9.5768e+00, -1.3122e+01],\n",
            "        [ 1.9334e-01, -2.4031e-01, -3.5085e-01, -2.0497e-01]],\n",
            "       requires_grad=True)\n",
            "l3.bias Parameter containing:\n",
            "tensor([-0.4066,  0.3024, -0.1746,  0.2661], requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}